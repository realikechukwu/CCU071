{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba19cc1e-0156-45b7-9cfa-dd307c0c9598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis notebook runs with pop_func function.\\nIt is a notebook that takes location_lad.csv file, downloaded from ONS nomis website.\\nhttps://www.nomisweb.co.uk/query/construct/components/stdListComponent.asp?menuopt=12&subcomp=100\\nthe above link takes you to the website to query ons population data to download relevant population per LAD per 5 year age bands.\\nHow I did this for London\\nIn Geography: select some local authority (districts)>choose region>london>tick all\\nIn Date: select years 2018 to 2023\\nIn age: scroll to individual ages and 5 year bands>select age 18, age 19 and age bands 20-85+\\nIn sex: select: total\\nConfirm selection in summary of selections\\nformat layout> as csv and download\\nThe resulting output is london_lad.csv below.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This notebook runs with pop_func function.\n",
    "It is a notebook that takes location_lad.csv file, downloaded from ONS nomis website.\n",
    "https://www.nomisweb.co.uk/query/construct/components/stdListComponent.asp?menuopt=12&subcomp=100\n",
    "the above link takes you to the website to query ons population data to download relevant population per LAD per 5 year age bands.\n",
    "How I did this for London\n",
    "In Geography: select some local authority (districts)>choose region>london>tick all\n",
    "In Date: select years 2018 to 2023\n",
    "In age: scroll to individual ages and 5 year bands>select age 18, age 19 and age bands 20-85+\n",
    "In sex: select: total\n",
    "Confirm selection in summary of selections\n",
    "format layout> as csv and download\n",
    "The resulting output is london_lad.csv below.\n",
    "The london_lad.csv is passed through the pipeline below to produce lon_pop_18_23.csv which is used in 2024 population prediction in SDE notebook\n",
    "used to age standardise.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c66a98d-ec3a-4534-8a4b-20ac9d3ce15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d50a74-052f-40ff-a256-c26de0a50d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pop_func.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d0b1aca-ec4e-4123-bef2-aad4f947429d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9',\n",
      "       'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13',\n",
      "       'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the full CSV\n",
    "df = pd.read_csv(\"london_lad.csv\")  # replace with your actual filename\n",
    "\n",
    "# Preview the columns\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4af45799-f5db-4bf4-9305-a284caa2f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows where a new year starts (e.g., look for rows with \"Date :\" or similar markers)\n",
    "year_rows = df[df.iloc[:, 0].str.contains(\"Date\", na=False)].index.tolist()\n",
    "\n",
    "# Add the end index for the final block\n",
    "year_rows.append(len(df))\n",
    "\n",
    "# Prepare a dictionary to store data for each year\n",
    "year_tables = {}\n",
    "\n",
    "# Loop through each year block\n",
    "for i in range(len(year_rows) - 1):\n",
    "    start = year_rows[i] + 1\n",
    "    end = year_rows[i + 1]\n",
    "\n",
    "    # Slice the dataframe for that year\n",
    "    year_df = df.iloc[start:end].copy()\n",
    "    \n",
    "    # Remove rows that are NaN or empty\n",
    "    year_df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    # The first row in this block is likely the column header\n",
    "    year_df.columns = year_df.iloc[0]\n",
    "    year_df = year_df[1:]\n",
    "\n",
    "    # Add LAD name column\n",
    "    year_df = year_df.rename(columns={year_df.columns[0]: \"lad\"})\n",
    "    \n",
    "    # Save it in dictionary\n",
    "    year = df.iloc[year_rows[i], 1]  # Assuming \"Date :\" is in col 0 and the year in col 1\n",
    "    year_tables[year] = year_df.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ef328c6-1d9b-426b-bce9-aad495024b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, table in year_tables.items():\n",
    "    table.to_csv(f\"df_{year}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b18c65fc-0713-4276-a87d-8ec4456eaad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: list of DataFrames\n",
    "dfs = ['df_2018', 'df_2019', 'df_2020', 'df_2021', 'df_2022', 'df_2023']\n",
    "table= []\n",
    "for df in dfs:\n",
    "    df =pd.read_csv(f\"{df}.csv\")\n",
    "    table.append(df)\n",
    "\n",
    "cleaned_tables = []\n",
    "\n",
    "for i, df in enumerate(table):\n",
    "    #here we clean the table to remove parts of the table that should not be in the final table\n",
    "    #we are removing rows 1 and last 2 rows if not df5, because df5 does not have an extra last row we only remove the top row\n",
    "    df.columns = df.iloc[0]  # Set first row as header\n",
    "    if i != 5:\n",
    "        df = df[1:-2]        # Drop first and last two rows\n",
    "    else:\n",
    "        df = df[1:]          # Drop only the first row\n",
    "    df = df.reset_index(drop=True)\n",
    "    cleaned_tables.append(df)\n",
    "\n",
    "for df in cleaned_tables:\n",
    "    df.rename(columns={df.columns[0]: 'lad'}, inplace=True)    \n",
    "\n",
    "# cleaned_tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c2b85bc-c1ad-494d-9f0d-7aba8606dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_tables = [df.T for df in cleaned_tables]\n",
    "\n",
    "# transposed_tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afdb805e-c6b3-4d35-b56d-c678ffad6f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tables = []\n",
    "\n",
    "for df in cleaned_tables:\n",
    "    df = df.copy()\n",
    "    df = df.set_index('lad')      # Make 'lad' the index temporarily to preserve it\n",
    "    df_t = df.T.reset_index()     # Transpose and bring index back as a column\n",
    "    df_t.columns.name = None      # Remove any name from columns (optional)\n",
    "    final_tables.append(df_t)\n",
    "\n",
    "for df in final_tables:\n",
    "    df.rename(columns={df.columns[0]: 'Age'}, inplace=True)\n",
    "    \n",
    "# final_tables[5]\n",
    "years = range(2018, 2024)\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    df = final_tables[i]\n",
    "    df.to_csv(f\"df_{year}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c44a0a87-ea36-4cdf-9184-0be6dbb230e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use\n",
    "file_paths = [f\"df_{year}.csv\" for year in range(2018, 2024)]\n",
    "lad_code_map = {\n",
    "    \"Barking and Dagenham\": \"E09000002\",\n",
    "    \"Barnet\": \"E09000003\",\n",
    "    \"Bexley\": \"E09000004\",\n",
    "    \"Brent\": \"E09000005\",\n",
    "    \"Bromley\": \"E09000006\",\n",
    "    \"Camden\": \"E09000007\",\n",
    "    \"City of London\": \"E09000001\",\n",
    "    \"Croydon\": \"E09000008\",\n",
    "    \"Ealing\": \"E09000009\",\n",
    "    \"Enfield\": \"E09000010\",\n",
    "    \"Greenwich\": \"E09000011\",\n",
    "    \"Hackney\": \"E09000012\",\n",
    "    \"Hammersmith and Fulham\": \"E09000013\",\n",
    "    \"Haringey\": \"E09000014\",\n",
    "    \"Harrow\": \"E09000015\",\n",
    "    \"Havering\": \"E09000016\",\n",
    "    \"Hillingdon\": \"E09000017\",\n",
    "    \"Hounslow\": \"E09000018\",\n",
    "    \"Islington\": \"E09000019\",\n",
    "    \"Kensington and Chelsea\": \"E09000020\",\n",
    "    \"Kingston upon Thames\": \"E09000021\",\n",
    "    \"Lambeth\": \"E09000022\",\n",
    "    \"Lewisham\": \"E09000023\",\n",
    "    \"Merton\": \"E09000024\",\n",
    "    \"Newham\": \"E09000025\",\n",
    "    \"Redbridge\": \"E09000026\",\n",
    "    \"Richmond upon Thames\": \"E09000027\",\n",
    "    \"Southwark\": \"E09000028\",\n",
    "    \"Sutton\": \"E09000029\",\n",
    "    \"Tower Hamlets\": \"E09000030\",\n",
    "    \"Waltham Forest\": \"E09000031\",\n",
    "    \"Wandsworth\": \"E09000032\",\n",
    "    \"Westminster\": \"E09000033\"\n",
    "}\n",
    "\n",
    "df_long = combine_pop_data(file_paths)\n",
    "transform_and_save_population_data(df_long, lad_code_map, \"lon_pop_18_23.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
